{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimax Lower Bounds for Transfer Learning with Linear and One-hidden Layer Neural Networks\n",
    "\n",
    "This Jupyter Notebook reproduces the numerical results in the paper *Minimax Lower Bounds for Transfer Learning with Linear and One-hidden Layer Neural Networks*. Before running this notebook, you need to install dependencies and download the datasets as described in the README. \n",
    "\n",
    "Each training task should take a couple of minutes to load the necessary training data before producing any output. \n",
    "\n",
    "Total run-time: about 15 minutes on a modern laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% Imports\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, set **DATASET_PATH** to the root folder you downloaded the datasets. The location set by **CHECKPOINT_PATH** will be used to save trained models and output data (about 100MB total). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% Folder setup\n"
    }
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = 'datasets' # Change this to the path to datasets root directory  \n",
    "CHECKPOINTS_PATH = 'checkpoints'  # Checkpoints will be saved in this folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we train a model on the source task *cat breeds*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% Train source model\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-29 12:28:45.839679: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-05-29 12:28:45.840046: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.\n",
      "Input shape:  (1620, 25088)\n",
      "Model: \"one_hidden\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden_layer (Linear)        multiple                  802848    \n",
      "_________________________________________________________________\n",
      "output_layer (Linear)        multiple                  165       \n",
      "=================================================================\n",
      "Total params: 803,013\n",
      "Trainable params: 802,848\n",
      "Non-trainable params: 165\n",
      "_________________________________________________________________\n",
      "val loss = 0.28600964 val accuracy = 0.24198718\n",
      "epoch 0: train mean loss = 0.3048781 train accuracy = 0.245679\n",
      "epoch 1: train mean loss = 0.24063754 train accuracy = 0.34567901\n",
      "epoch 2: train mean loss = 0.20382969 train accuracy = 0.41234568\n",
      "epoch 3: train mean loss = 0.17748822 train accuracy = 0.48518518\n",
      "epoch 4: train mean loss = 0.15817839 train accuracy = 0.53765434\n",
      "epoch 5: train mean loss = 0.14172691 train accuracy = 0.59753084\n",
      "epoch 6: train mean loss = 0.12793101 train accuracy = 0.6419753\n",
      "epoch 7: train mean loss = 0.11593321 train accuracy = 0.6864197\n",
      "epoch 8: train mean loss = 0.10602807 train accuracy = 0.72407407\n",
      "epoch 9: train mean loss = 0.0968419 train accuracy = 0.75493824\n",
      "val loss = 0.21659134 val accuracy = 0.4415064\n",
      "epoch 10: train mean loss = 0.08977877 train accuracy = 0.7888889\n",
      "epoch 11: train mean loss = 0.08238765 train accuracy = 0.8104938\n",
      "epoch 12: train mean loss = 0.07649938 train accuracy = 0.8358025\n",
      "epoch 13: train mean loss = 0.07011856 train accuracy = 0.85123456\n",
      "epoch 14: train mean loss = 0.06536789 train accuracy = 0.8660494\n",
      "epoch 15: train mean loss = 0.06100116 train accuracy = 0.8833333\n",
      "epoch 16: train mean loss = 0.056344483 train accuracy = 0.8993827\n",
      "epoch 17: train mean loss = 0.053582843 train accuracy = 0.90925926\n",
      "epoch 18: train mean loss = 0.049785953 train accuracy = 0.9191358\n",
      "epoch 19: train mean loss = 0.04673607 train accuracy = 0.9327161\n",
      "val loss = 0.2052688 val accuracy = 0.47235575\n",
      "epoch 20: train mean loss = 0.044419233 train accuracy = 0.9425926\n",
      "epoch 21: train mean loss = 0.04140157 train accuracy = 0.94814813\n",
      "epoch 22: train mean loss = 0.039299607 train accuracy = 0.9537037\n",
      "epoch 23: train mean loss = 0.036764853 train accuracy = 0.95987654\n",
      "epoch 24: train mean loss = 0.03480548 train accuracy = 0.962963\n",
      "epoch 25: train mean loss = 0.033143856 train accuracy = 0.97037035\n",
      "epoch 26: train mean loss = 0.03160894 train accuracy = 0.9765432\n",
      "epoch 27: train mean loss = 0.029480176 train accuracy = 0.97962964\n",
      "epoch 28: train mean loss = 0.028101912 train accuracy = 0.9808642\n",
      "epoch 29: train mean loss = 0.027263092 train accuracy = 0.9814815\n",
      "val loss = 0.2011019 val accuracy = 0.4815705\n",
      "epoch 30: train mean loss = 0.025692638 train accuracy = 0.982716\n",
      "epoch 31: train mean loss = 0.024715926 train accuracy = 0.9839506\n",
      "epoch 32: train mean loss = 0.023163715 train accuracy = 0.9858025\n",
      "epoch 33: train mean loss = 0.021991314 train accuracy = 0.9882716\n",
      "epoch 34: train mean loss = 0.020974632 train accuracy = 0.9895062\n",
      "epoch 35: train mean loss = 0.020232469 train accuracy = 0.99012345\n",
      "epoch 36: train mean loss = 0.019360952 train accuracy = 0.9907407\n",
      "epoch 37: train mean loss = 0.018558519 train accuracy = 0.9919753\n",
      "epoch 38: train mean loss = 0.01791953 train accuracy = 0.9925926\n",
      "epoch 39: train mean loss = 0.017027088 train accuracy = 0.9932099\n",
      "val loss = 0.1990409 val accuracy = 0.51121795\n",
      "epoch 40: train mean loss = 0.016283395 train accuracy = 0.9932099\n",
      "epoch 41: train mean loss = 0.015579096 train accuracy = 0.99382716\n",
      "epoch 42: train mean loss = 0.015162488 train accuracy = 0.99382716\n",
      "epoch 43: train mean loss = 0.014380381 train accuracy = 0.99444443\n",
      "epoch 44: train mean loss = 0.013929693 train accuracy = 0.99444443\n",
      "epoch 45: train mean loss = 0.013411784 train accuracy = 0.99444443\n",
      "epoch 46: train mean loss = 0.012853385 train accuracy = 0.995679\n",
      "Goal accuracy reached. Stopping training. \n",
      "Final val loss = 0.1982931 val accuracy = 0.5048077\n",
      "Saving model...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "!python train_model.py --checkpoint-path {os.path.join(CHECKPOINTS_PATH, 'source_catbreeds/model')} \\\n",
    "            --data-path {os.path.join(DATASET_PATH,'catbreeds')} \\\n",
    "            --hidden-units 32 \\\n",
    "            --use-bias \\\n",
    "            --freeze-output-layer \\\n",
    "            --epochs 100 \\\n",
    "            --stop-at-acc 0.995 \\\n",
    "            --optimizer adam \\\n",
    "            --lr 0.0001 \\\n",
    "            --shuffle \\\n",
    "            --seed 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train a separate model for each individual target task.\n",
    "We use the saved source model to load the fixed output layer weights before training, and to make sure that target and source architectures match. The source model's trained weights are not used in any way.\n",
    "Training *big cats*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% Train target model: 'big cats'\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-29 12:30:20.431992: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-05-29 12:30:20.432371: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.\n",
      "Input shape:  (1620, 25088)\n",
      "Model: \"one_hidden_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden_layer (Linear)        multiple                  802848    \n",
      "_________________________________________________________________\n",
      "output_layer (Linear)        multiple                  165       \n",
      "=================================================================\n",
      "Total params: 803,013\n",
      "Trainable params: 802,848\n",
      "Non-trainable params: 165\n",
      "_________________________________________________________________\n",
      "val loss = 0.25079572 val accuracy = 0.2684295\n",
      "epoch 0: train mean loss = 0.26987818 train accuracy = 0.25925925\n",
      "epoch 1: train mean loss = 0.17508039 train accuracy = 0.49814814\n",
      "epoch 2: train mean loss = 0.13481186 train accuracy = 0.60555553\n",
      "epoch 3: train mean loss = 0.11059046 train accuracy = 0.7024691\n",
      "epoch 4: train mean loss = 0.09358588 train accuracy = 0.77098763\n",
      "epoch 5: train mean loss = 0.08120307 train accuracy = 0.82345676\n",
      "epoch 6: train mean loss = 0.07136633 train accuracy = 0.8635802\n",
      "epoch 7: train mean loss = 0.06432093 train accuracy = 0.8901235\n",
      "epoch 8: train mean loss = 0.057728667 train accuracy = 0.91049385\n",
      "epoch 9: train mean loss = 0.0518822 train accuracy = 0.9314815\n",
      "val loss = 0.18023318 val accuracy = 0.48076925\n",
      "epoch 10: train mean loss = 0.048008528 train accuracy = 0.945679\n",
      "epoch 11: train mean loss = 0.04370474 train accuracy = 0.95555556\n",
      "epoch 12: train mean loss = 0.040170554 train accuracy = 0.9617284\n",
      "epoch 13: train mean loss = 0.03731331 train accuracy = 0.9697531\n",
      "epoch 14: train mean loss = 0.034328684 train accuracy = 0.9771605\n",
      "epoch 15: train mean loss = 0.032267068 train accuracy = 0.9808642\n",
      "epoch 16: train mean loss = 0.03042722 train accuracy = 0.98703706\n",
      "epoch 17: train mean loss = 0.028330352 train accuracy = 0.99012345\n",
      "epoch 18: train mean loss = 0.026436467 train accuracy = 0.99135804\n",
      "epoch 19: train mean loss = 0.024668047 train accuracy = 0.9919753\n",
      "val loss = 0.16968083 val accuracy = 0.51842946\n",
      "epoch 20: train mean loss = 0.023168135 train accuracy = 0.9925926\n",
      "epoch 21: train mean loss = 0.022093466 train accuracy = 0.9932099\n",
      "epoch 22: train mean loss = 0.020968823 train accuracy = 0.99444443\n",
      "epoch 23: train mean loss = 0.019661065 train accuracy = 0.99506176\n",
      "Goal accuracy reached. Stopping training. \n",
      "Final val loss = 0.1681584 val accuracy = 0.5248397\n",
      "Final model distance:  12.346081112236561\n",
      "Saving model...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "!python train_model.py --checkpoint-path {os.path.join(CHECKPOINTS_PATH, 'bigcats/model')} \\\n",
    "                        --data-path {os.path.join(DATASET_PATH,'bigcats')} \\\n",
    "                        --load-layer \\\n",
    "                        --layer-to-train hidden \\\n",
    "                        --source-checkpoint {os.path.join(CHECKPOINTS_PATH, 'source_catbreeds/model')} \\\n",
    "                        --stop-at-acc  0.995 \\\n",
    "                        --epochs 100 \\\n",
    "                        --optimizer adam \\\n",
    "                        --lr 0.0001 \\\n",
    "                        --shuffle \\\n",
    "                        --seed 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Training *dog breeds*:\n",
    " We switch two class labels in the *dog breeds* dataset to align similar classes with the source dataset.\n",
    " In *big cats* the default class labeling already provides a good alignment,\n",
    " and the other datasets are semantically too far from the source to\n",
    " find a good class alignment a priori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% Train target models: 'dog breeds'\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-29 12:31:36.584293: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-05-29 12:31:36.584663: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.\n",
      "Input shape:  (1620, 25088)\n",
      "Model: \"one_hidden_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden_layer (Linear)        multiple                  802848    \n",
      "_________________________________________________________________\n",
      "output_layer (Linear)        multiple                  165       \n",
      "=================================================================\n",
      "Total params: 803,013\n",
      "Trainable params: 802,848\n",
      "Non-trainable params: 165\n",
      "_________________________________________________________________\n",
      "val loss = 0.2875681 val accuracy = 0.2676282\n",
      "epoch 0: train mean loss = 0.3062117 train accuracy = 0.24691358\n",
      "epoch 1: train mean loss = 0.18633427 train accuracy = 0.48271605\n",
      "epoch 2: train mean loss = 0.13644426 train accuracy = 0.6388889\n",
      "epoch 3: train mean loss = 0.10908199 train accuracy = 0.73703706\n",
      "epoch 4: train mean loss = 0.09077216 train accuracy = 0.8191358\n",
      "epoch 5: train mean loss = 0.076431446 train accuracy = 0.8716049\n",
      "epoch 6: train mean loss = 0.06707735 train accuracy = 0.9123457\n",
      "epoch 7: train mean loss = 0.058419578 train accuracy = 0.94012344\n",
      "epoch 8: train mean loss = 0.051758412 train accuracy = 0.95308644\n",
      "epoch 9: train mean loss = 0.04642695 train accuracy = 0.96728396\n",
      "val loss = 0.22518516 val accuracy = 0.4334936\n",
      "epoch 10: train mean loss = 0.041961692 train accuracy = 0.97839504\n",
      "epoch 11: train mean loss = 0.038313635 train accuracy = 0.9845679\n",
      "epoch 12: train mean loss = 0.03456686 train accuracy = 0.98641974\n",
      "epoch 13: train mean loss = 0.03179039 train accuracy = 0.9876543\n",
      "epoch 14: train mean loss = 0.029176744 train accuracy = 0.98888886\n",
      "epoch 15: train mean loss = 0.026764423 train accuracy = 0.9932099\n",
      "epoch 16: train mean loss = 0.024534406 train accuracy = 0.99382716\n",
      "epoch 17: train mean loss = 0.02297178 train accuracy = 0.99382716\n",
      "epoch 18: train mean loss = 0.021278726 train accuracy = 0.99506176\n",
      "Goal accuracy reached. Stopping training. \n",
      "Final val loss = 0.21942268 val accuracy = 0.4451122\n",
      "Final model distance:  11.618599329175604\n",
      "Saving model...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "!python train_model.py --checkpoint-path {os.path.join(CHECKPOINTS_PATH, 'dogbreeds/model')} \\\n",
    "                        --data-path {os.path.join(DATASET_PATH,'dogbreeds')} \\\n",
    "                        --load-layer \\\n",
    "                        --layer-to-train hidden \\\n",
    "                        --source-checkpoint {os.path.join(CHECKPOINTS_PATH, 'source_catbreeds/model')} \\\n",
    "                        --map-train-labels 1 0 2 3 4 \\\n",
    "                        --map-test-labels 1 0 2 3 4 \\\n",
    "                        --stop-at-acc  0.995 \\\n",
    "                        --epochs 100 \\\n",
    "                        --optimizer adam \\\n",
    "                        --lr 0.0001 \\\n",
    "                        --shuffle \\\n",
    "                        --seed 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training *butterflies*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% Train target models: 'butterflies'\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-29 12:32:40.527645: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-05-29 12:32:40.528054: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.\n",
      "Input shape:  (1620, 25088)\n",
      "Model: \"one_hidden_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden_layer (Linear)        multiple                  802848    \n",
      "_________________________________________________________________\n",
      "output_layer (Linear)        multiple                  165       \n",
      "=================================================================\n",
      "Total params: 803,013\n",
      "Trainable params: 802,848\n",
      "Non-trainable params: 165\n",
      "_________________________________________________________________\n",
      "val loss = 0.20465107 val accuracy = 0.630609\n",
      "epoch 0: train mean loss = 0.2783453 train accuracy = 0.35246915\n",
      "epoch 1: train mean loss = 0.16254473 train accuracy = 0.6333333\n",
      "epoch 2: train mean loss = 0.11928726 train accuracy = 0.7197531\n",
      "epoch 3: train mean loss = 0.095696464 train accuracy = 0.78641975\n",
      "epoch 4: train mean loss = 0.07916136 train accuracy = 0.8388889\n",
      "epoch 5: train mean loss = 0.06702633 train accuracy = 0.86975306\n",
      "epoch 6: train mean loss = 0.057726867 train accuracy = 0.891358\n",
      "epoch 7: train mean loss = 0.05103279 train accuracy = 0.9197531\n",
      "epoch 8: train mean loss = 0.04514794 train accuracy = 0.9308642\n",
      "epoch 9: train mean loss = 0.040254906 train accuracy = 0.9444444\n",
      "val loss = 0.1448072 val accuracy = 0.7395833\n",
      "epoch 10: train mean loss = 0.036708955 train accuracy = 0.95555556\n",
      "epoch 11: train mean loss = 0.033011623 train accuracy = 0.9654321\n",
      "epoch 12: train mean loss = 0.030301183 train accuracy = 0.9697531\n",
      "epoch 13: train mean loss = 0.02806313 train accuracy = 0.97407407\n",
      "epoch 14: train mean loss = 0.025373766 train accuracy = 0.9808642\n",
      "epoch 15: train mean loss = 0.02327289 train accuracy = 0.9858025\n",
      "epoch 16: train mean loss = 0.021545483 train accuracy = 0.9882716\n",
      "epoch 17: train mean loss = 0.020031132 train accuracy = 0.99135804\n",
      "epoch 18: train mean loss = 0.018467842 train accuracy = 0.99135804\n",
      "epoch 19: train mean loss = 0.017158968 train accuracy = 0.9932099\n",
      "val loss = 0.13785337 val accuracy = 0.7616186\n",
      "epoch 20: train mean loss = 0.016101494 train accuracy = 0.9932099\n",
      "epoch 21: train mean loss = 0.0150725525 train accuracy = 0.9932099\n",
      "epoch 22: train mean loss = 0.01421186 train accuracy = 0.99444443\n",
      "epoch 23: train mean loss = 0.0130409105 train accuracy = 0.99444443\n",
      "epoch 24: train mean loss = 0.012271433 train accuracy = 0.99506176\n",
      "Goal accuracy reached. Stopping training. \n",
      "Final val loss = 0.13667554 val accuracy = 0.7668269\n",
      "Final model distance:  13.476666987805517\n",
      "Saving model...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "!python train_model.py --checkpoint-path {os.path.join(CHECKPOINTS_PATH, 'butterflies/model')} \\\n",
    "                        --data-path {os.path.join(DATASET_PATH,'butterflies')} \\\n",
    "                        --load-layer \\\n",
    "                        --layer-to-train hidden \\\n",
    "                        --source-checkpoint {os.path.join(CHECKPOINTS_PATH, 'source_catbreeds/model')} \\\n",
    "                        --stop-at-acc  0.995 \\\n",
    "                        --epochs 100 \\\n",
    "                        --optimizer adam \\\n",
    "                        --lr 0.0001 \\\n",
    "                        --shuffle \\\n",
    "                        --seed 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training *planes*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% Train target model: 'planes'\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-29 12:33:55.407284: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-05-29 12:33:55.407654: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.\n",
      "Input shape:  (1620, 25088)\n",
      "Model: \"one_hidden_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden_layer (Linear)        multiple                  802848    \n",
      "_________________________________________________________________\n",
      "output_layer (Linear)        multiple                  165       \n",
      "=================================================================\n",
      "Total params: 803,013\n",
      "Trainable params: 802,848\n",
      "Non-trainable params: 165\n",
      "_________________________________________________________________\n",
      "val loss = 0.21643943 val accuracy = 0.35576925\n",
      "epoch 0: train mean loss = 0.261832 train accuracy = 0.26728395\n",
      "epoch 1: train mean loss = 0.16861589 train accuracy = 0.4808642\n",
      "epoch 2: train mean loss = 0.12943389 train accuracy = 0.6006173\n",
      "epoch 3: train mean loss = 0.10545044 train accuracy = 0.7154321\n",
      "epoch 4: train mean loss = 0.08989275 train accuracy = 0.7919753\n",
      "epoch 5: train mean loss = 0.077176705 train accuracy = 0.85617286\n",
      "epoch 6: train mean loss = 0.0684689 train accuracy = 0.89506173\n",
      "epoch 7: train mean loss = 0.06127357 train accuracy = 0.9166667\n",
      "epoch 8: train mean loss = 0.05517421 train accuracy = 0.9364197\n",
      "epoch 9: train mean loss = 0.050339714 train accuracy = 0.94876546\n",
      "val loss = 0.15121347 val accuracy = 0.5813301\n",
      "epoch 10: train mean loss = 0.046231057 train accuracy = 0.95555556\n",
      "epoch 11: train mean loss = 0.04228367 train accuracy = 0.9641975\n",
      "epoch 12: train mean loss = 0.039681382 train accuracy = 0.96666664\n",
      "epoch 13: train mean loss = 0.03695781 train accuracy = 0.9722222\n",
      "epoch 14: train mean loss = 0.034408756 train accuracy = 0.9734568\n",
      "epoch 15: train mean loss = 0.032179 train accuracy = 0.9765432\n",
      "epoch 16: train mean loss = 0.030245047 train accuracy = 0.9808642\n",
      "epoch 17: train mean loss = 0.02810755 train accuracy = 0.9814815\n",
      "epoch 18: train mean loss = 0.02660519 train accuracy = 0.98333335\n",
      "epoch 19: train mean loss = 0.025398863 train accuracy = 0.9858025\n",
      "val loss = 0.1456689 val accuracy = 0.6201923\n",
      "epoch 20: train mean loss = 0.02374912 train accuracy = 0.98703706\n",
      "epoch 21: train mean loss = 0.022570511 train accuracy = 0.9876543\n",
      "epoch 22: train mean loss = 0.021504985 train accuracy = 0.9876543\n",
      "epoch 23: train mean loss = 0.020302497 train accuracy = 0.9876543\n",
      "epoch 24: train mean loss = 0.019151686 train accuracy = 0.98703706\n",
      "epoch 25: train mean loss = 0.018422075 train accuracy = 0.9876543\n",
      "epoch 26: train mean loss = 0.017532019 train accuracy = 0.9882716\n",
      "epoch 27: train mean loss = 0.016825162 train accuracy = 0.9882716\n",
      "epoch 28: train mean loss = 0.016099224 train accuracy = 0.9895062\n",
      "epoch 29: train mean loss = 0.015357588 train accuracy = 0.9882716\n",
      "val loss = 0.14407647 val accuracy = 0.6266026\n",
      "epoch 30: train mean loss = 0.014721566 train accuracy = 0.98703706\n",
      "epoch 31: train mean loss = 0.014065493 train accuracy = 0.9882716\n",
      "epoch 32: train mean loss = 0.013498576 train accuracy = 0.9882716\n",
      "epoch 33: train mean loss = 0.013200364 train accuracy = 0.9882716\n",
      "epoch 34: train mean loss = 0.012559559 train accuracy = 0.98888886\n",
      "epoch 35: train mean loss = 0.012110309 train accuracy = 0.98888886\n",
      "epoch 36: train mean loss = 0.011782914 train accuracy = 0.9895062\n",
      "epoch 37: train mean loss = 0.011390011 train accuracy = 0.9876543\n",
      "epoch 38: train mean loss = 0.010863583 train accuracy = 0.99012345\n",
      "epoch 39: train mean loss = 0.010483678 train accuracy = 0.9907407\n",
      "val loss = 0.14369108 val accuracy = 0.63301283\n",
      "epoch 40: train mean loss = 0.0102022635 train accuracy = 0.9907407\n",
      "epoch 41: train mean loss = 0.009862027 train accuracy = 0.9907407\n",
      "epoch 42: train mean loss = 0.009551469 train accuracy = 0.9919753\n",
      "epoch 43: train mean loss = 0.009100761 train accuracy = 0.9919753\n",
      "epoch 44: train mean loss = 0.008734304 train accuracy = 0.9907407\n",
      "epoch 45: train mean loss = 0.008445406 train accuracy = 0.99135804\n",
      "epoch 46: train mean loss = 0.008293667 train accuracy = 0.98888886\n",
      "epoch 47: train mean loss = 0.008030546 train accuracy = 0.99135804\n",
      "epoch 48: train mean loss = 0.007652441 train accuracy = 0.9895062\n",
      "epoch 49: train mean loss = 0.007573044 train accuracy = 0.99135804\n",
      "val loss = 0.14370489 val accuracy = 0.63301283\n",
      "epoch 50: train mean loss = 0.0072390055 train accuracy = 0.99012345\n",
      "epoch 51: train mean loss = 0.0075183343 train accuracy = 0.99012345\n",
      "epoch 52: train mean loss = 0.00702487 train accuracy = 0.99012345\n",
      "epoch 53: train mean loss = 0.00691778 train accuracy = 0.99135804\n",
      "epoch 54: train mean loss = 0.0065583433 train accuracy = 0.9907407\n",
      "epoch 55: train mean loss = 0.0064791264 train accuracy = 0.9907407\n",
      "epoch 56: train mean loss = 0.006174883 train accuracy = 0.9919753\n",
      "epoch 57: train mean loss = 0.006090974 train accuracy = 0.9919753\n",
      "epoch 58: train mean loss = 0.005986574 train accuracy = 0.9907407\n",
      "epoch 59: train mean loss = 0.005715052 train accuracy = 0.9919753\n",
      "val loss = 0.14400114 val accuracy = 0.62259614\n",
      "epoch 60: train mean loss = 0.0055435044 train accuracy = 0.9919753\n",
      "epoch 61: train mean loss = 0.005642432 train accuracy = 0.99012345\n",
      "epoch 62: train mean loss = 0.005219959 train accuracy = 0.99135804\n",
      "epoch 63: train mean loss = 0.00524188 train accuracy = 0.9919753\n",
      "epoch 64: train mean loss = 0.0050801346 train accuracy = 0.99135804\n",
      "epoch 65: train mean loss = 0.004999689 train accuracy = 0.98888886\n",
      "epoch 66: train mean loss = 0.004762913 train accuracy = 0.9895062\n",
      "epoch 67: train mean loss = 0.004693712 train accuracy = 0.99012345\n",
      "epoch 68: train mean loss = 0.0045709223 train accuracy = 0.9919753\n",
      "epoch 69: train mean loss = 0.0044159233 train accuracy = 0.99012345\n",
      "val loss = 0.14404772 val accuracy = 0.63822114\n",
      "epoch 70: train mean loss = 0.0043715467 train accuracy = 0.99012345\n",
      "epoch 71: train mean loss = 0.0042979573 train accuracy = 0.9907407\n",
      "epoch 72: train mean loss = 0.004214746 train accuracy = 0.99012345\n",
      "epoch 73: train mean loss = 0.004170676 train accuracy = 0.9907407\n",
      "epoch 74: train mean loss = 0.004131249 train accuracy = 0.9895062\n",
      "epoch 75: train mean loss = 0.004273754 train accuracy = 0.9919753\n",
      "epoch 76: train mean loss = 0.003891447 train accuracy = 0.99135804\n",
      "epoch 77: train mean loss = 0.0038260752 train accuracy = 0.99012345\n",
      "epoch 78: train mean loss = 0.003962319 train accuracy = 0.9907407\n",
      "epoch 79: train mean loss = 0.0036797966 train accuracy = 0.99012345\n",
      "val loss = 0.14417966 val accuracy = 0.6498397\n",
      "epoch 80: train mean loss = 0.003637576 train accuracy = 0.99135804\n",
      "epoch 81: train mean loss = 0.0035787076 train accuracy = 0.9895062\n",
      "epoch 82: train mean loss = 0.0034831231 train accuracy = 0.9882716\n",
      "epoch 83: train mean loss = 0.0035432903 train accuracy = 0.98888886\n",
      "epoch 84: train mean loss = 0.0034991936 train accuracy = 0.9895062\n",
      "epoch 85: train mean loss = 0.0033478262 train accuracy = 0.99012345\n",
      "epoch 86: train mean loss = 0.0032180985 train accuracy = 0.9907407\n",
      "epoch 87: train mean loss = 0.0031760165 train accuracy = 0.9907407\n",
      "epoch 88: train mean loss = 0.0032780764 train accuracy = 0.9907407\n",
      "epoch 89: train mean loss = 0.0030785075 train accuracy = 0.99012345\n",
      "val loss = 0.14449354 val accuracy = 0.6498397\n",
      "epoch 90: train mean loss = 0.0031143008 train accuracy = 0.9907407\n",
      "epoch 91: train mean loss = 0.0030288722 train accuracy = 0.9907407\n",
      "epoch 92: train mean loss = 0.002941206 train accuracy = 0.99012345\n",
      "epoch 93: train mean loss = 0.0028956193 train accuracy = 0.9895062\n",
      "epoch 94: train mean loss = 0.0030186302 train accuracy = 0.9876543\n",
      "epoch 95: train mean loss = 0.0030701628 train accuracy = 0.98888886\n",
      "epoch 96: train mean loss = 0.0028011096 train accuracy = 0.9907407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 97: train mean loss = 0.002818961 train accuracy = 0.99135804\n",
      "epoch 98: train mean loss = 0.0027094847 train accuracy = 0.99135804\n",
      "epoch 99: train mean loss = 0.0027785886 train accuracy = 0.9907407\n",
      "Final val loss = 0.14492278 val accuracy = 0.6498397\n",
      "Final model distance:  16.40820744517008\n",
      "Saving model...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "!python train_model.py --checkpoint-path {os.path.join(CHECKPOINTS_PATH, 'planes/model')} \\\n",
    "                        --data-path {os.path.join(DATASET_PATH,'planes')} \\\n",
    "                        --load-layer \\\n",
    "                        --layer-to-train hidden \\\n",
    "                        --source-checkpoint {os.path.join(CHECKPOINTS_PATH, 'source_catbreeds/model')} \\\n",
    "                        --stop-at-acc  0.995 \\\n",
    "                        --epochs 100 \\\n",
    "                        --optimizer adam \\\n",
    "                        --lr 0.0001 \\\n",
    "                        --shuffle \\\n",
    "                        --seed 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell collects results from previous models in order to reproduce results for Table 1 in the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% Evaluate distance between source and target models and final validation loss.\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target  checkpoints/dogbreeds/model : distance=  11.618599329175604  final val. loss:  0.21942268\n",
      "Target  checkpoints/bigcats/model : distance=  12.346081112236561  final val. loss:  0.1681584\n",
      "Target  checkpoints/butterflies/model : distance=  13.476666987805517  final val. loss:  0.13667554\n",
      "Target  checkpoints/planes/model : distance=  16.40820744517008  final val. loss:  0.14492278\n"
     ]
    }
   ],
   "source": [
    "source_checkpoint =  os.path.join(CHECKPOINTS_PATH, 'source_catbreeds/model')\n",
    "target_checkpoints = [os.path.join(CHECKPOINTS_PATH, 'dogbreeds/model'),\n",
    "                      os.path.join(CHECKPOINTS_PATH, 'bigcats/model'),\n",
    "                      os.path.join(CHECKPOINTS_PATH, 'butterflies/model'),\n",
    "                      os.path.join(CHECKPOINTS_PATH, 'planes/model')]\n",
    "\n",
    "for t in target_checkpoints:\n",
    "    target_folder = str(Path(t).parent)\n",
    "    save_path = target_folder+ '/results_'+ str(Path(t).name)+'.npz'\n",
    "    results = np.load(save_path, allow_pickle=True)['arr_0'].item()\n",
    "    final_val_loss = results['val_loss'][-1]\n",
    "    dist = results['distance']\n",
    "    print('Target ', t, ': distance= ', dist, ' final val. loss: ', final_val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we test how well the source model performs on the target tasks without using any target examples for training. Train on *cat breeds* and validate on *big cats*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% Train source and validate on each target task\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-29 12:37:06.395180: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-05-29 12:37:06.395545: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.\n",
      "Input shape:  (1620, 25088)\n",
      "Model: \"one_hidden\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden_layer (Linear)        multiple                  802848    \n",
      "_________________________________________________________________\n",
      "output_layer (Linear)        multiple                  165       \n",
      "=================================================================\n",
      "Total params: 803,013\n",
      "Trainable params: 802,848\n",
      "Non-trainable params: 165\n",
      "_________________________________________________________________\n",
      "val loss = 0.2718821 val accuracy = 0.2459936\n",
      "epoch 0: train mean loss = 0.275201 train accuracy = 0.25555557\n",
      "val loss = 0.2679388 val accuracy = 0.23317307\n",
      "epoch 1: train mean loss = 0.21246846 train accuracy = 0.38271606\n",
      "val loss = 0.26478052 val accuracy = 0.24358974\n",
      "epoch 2: train mean loss = 0.17861284 train accuracy = 0.48209876\n",
      "val loss = 0.26204222 val accuracy = 0.24879807\n",
      "epoch 3: train mean loss = 0.15325956 train accuracy = 0.55246913\n",
      "val loss = 0.26122478 val accuracy = 0.27083334\n",
      "epoch 4: train mean loss = 0.13507222 train accuracy = 0.61851853\n",
      "val loss = 0.2608489 val accuracy = 0.265625\n",
      "epoch 5: train mean loss = 0.11893991 train accuracy = 0.6808642\n",
      "val loss = 0.2601157 val accuracy = 0.27083334\n",
      "epoch 6: train mean loss = 0.105513684 train accuracy = 0.7475309\n",
      "val loss = 0.259047 val accuracy = 0.27483973\n",
      "epoch 7: train mean loss = 0.09541909 train accuracy = 0.7882716\n",
      "val loss = 0.2579248 val accuracy = 0.28125\n",
      "epoch 8: train mean loss = 0.085875146 train accuracy = 0.8358025\n",
      "val loss = 0.25832602 val accuracy = 0.27483973\n",
      "epoch 9: train mean loss = 0.07846173 train accuracy = 0.8654321\n",
      "Final val loss = 0.25832602 val accuracy = 0.27483973\n",
      "Saving model...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "!python train_model.py --checkpoint-path {os.path.join(CHECKPOINTS_PATH, 'target_valid/catbreeds_to_bigcats/model')} \\\n",
    "                    --data-path {os.path.join(DATASET_PATH,'bigcats')} \\\n",
    "                    --mix-datasets \\\n",
    "                    --mix-data-path {os.path.join(DATASET_PATH,'catbreeds')} \\\n",
    "                    --hidden-units 32 \\\n",
    "                    --use-bias \\\n",
    "                    --freeze-output-layer \\\n",
    "                    --epochs 10 \\\n",
    "                    --val-freq 1 \\\n",
    "                    --optimizer adam \\\n",
    "                    --lr 0.0001 \\\n",
    "                    --shuffle \\\n",
    "                    --seed 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on *cat breeds* and validate on *dog breeds*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% Validate on 'dog breeds'\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-29 12:38:12.107167: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-05-29 12:38:12.107579: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.\n",
      "Input shape:  (1620, 25088)\n",
      "Model: \"one_hidden\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden_layer (Linear)        multiple                  802848    \n",
      "_________________________________________________________________\n",
      "output_layer (Linear)        multiple                  165       \n",
      "=================================================================\n",
      "Total params: 803,013\n",
      "Trainable params: 802,848\n",
      "Non-trainable params: 165\n",
      "_________________________________________________________________\n",
      "val loss = 0.30716613 val accuracy = 0.2139423\n",
      "epoch 0: train mean loss = 0.275201 train accuracy = 0.25555557\n",
      "val loss = 0.29478163 val accuracy = 0.21514423\n",
      "epoch 1: train mean loss = 0.21246846 train accuracy = 0.38271606\n",
      "val loss = 0.2884213 val accuracy = 0.22435898\n",
      "epoch 2: train mean loss = 0.17861284 train accuracy = 0.48209876\n",
      "val loss = 0.28386563 val accuracy = 0.22836538\n",
      "epoch 3: train mean loss = 0.15325956 train accuracy = 0.55246913\n",
      "val loss = 0.28080928 val accuracy = 0.25440705\n",
      "epoch 4: train mean loss = 0.13507222 train accuracy = 0.61851853\n",
      "val loss = 0.27825218 val accuracy = 0.26602563\n",
      "epoch 5: train mean loss = 0.11893991 train accuracy = 0.6808642\n",
      "val loss = 0.27715242 val accuracy = 0.27123398\n",
      "epoch 6: train mean loss = 0.105513684 train accuracy = 0.7475309\n",
      "val loss = 0.27527303 val accuracy = 0.27003205\n",
      "epoch 7: train mean loss = 0.09541909 train accuracy = 0.7882716\n",
      "val loss = 0.27483872 val accuracy = 0.27123398\n",
      "epoch 8: train mean loss = 0.085875146 train accuracy = 0.8358025\n",
      "val loss = 0.2742748 val accuracy = 0.2752404\n",
      "epoch 9: train mean loss = 0.07846173 train accuracy = 0.8654321\n",
      "Final val loss = 0.2742748 val accuracy = 0.2752404\n",
      "Saving model...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "!python train_model.py --checkpoint-path {os.path.join(CHECKPOINTS_PATH, 'target_valid/catbreeds_to_dogbreeds/model')} \\\n",
    "                    --data-path {os.path.join(DATASET_PATH,'dogbreeds')} \\\n",
    "                    --mix-datasets \\\n",
    "                    --mix-data-path {os.path.join(DATASET_PATH,'catbreeds')} \\\n",
    "                    --hidden-units 32 \\\n",
    "                    --use-bias \\\n",
    "                    --freeze-output-layer \\\n",
    "                    --map-test-labels 1 0 2 3 4 \\\n",
    "                    --epochs 10 \\\n",
    "                    --val-freq 1 \\\n",
    "                    --optimizer adam \\\n",
    "                    --lr 0.0001 \\\n",
    "                    --shuffle \\\n",
    "                    --seed 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on *cat breeds* and validate on *butterflies*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% Validate on 'butterflies'\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-29 12:39:17.594295: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-05-29 12:39:17.594700: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.\n",
      "Input shape:  (1620, 25088)\n",
      "Model: \"one_hidden\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden_layer (Linear)        multiple                  802848    \n",
      "_________________________________________________________________\n",
      "output_layer (Linear)        multiple                  165       \n",
      "=================================================================\n",
      "Total params: 803,013\n",
      "Trainable params: 802,848\n",
      "Non-trainable params: 165\n",
      "_________________________________________________________________\n",
      "val loss = 0.29537886 val accuracy = 0.25360575\n",
      "epoch 0: train mean loss = 0.275201 train accuracy = 0.25555557\n",
      "val loss = 0.28742543 val accuracy = 0.26001602\n",
      "epoch 1: train mean loss = 0.21246846 train accuracy = 0.38271606\n",
      "val loss = 0.28265867 val accuracy = 0.2588141\n",
      "epoch 2: train mean loss = 0.17861284 train accuracy = 0.48209876\n",
      "val loss = 0.27847433 val accuracy = 0.2459936\n",
      "epoch 3: train mean loss = 0.15325956 train accuracy = 0.55246913\n",
      "val loss = 0.2759683 val accuracy = 0.2383814\n",
      "epoch 4: train mean loss = 0.13507222 train accuracy = 0.61851853\n",
      "val loss = 0.27487132 val accuracy = 0.23958333\n",
      "epoch 5: train mean loss = 0.11893991 train accuracy = 0.6808642\n",
      "val loss = 0.27417076 val accuracy = 0.22676282\n",
      "epoch 6: train mean loss = 0.105513684 train accuracy = 0.7475309\n",
      "val loss = 0.2730024 val accuracy = 0.23197114\n",
      "epoch 7: train mean loss = 0.09541909 train accuracy = 0.7882716\n",
      "val loss = 0.27229166 val accuracy = 0.22035258\n",
      "epoch 8: train mean loss = 0.085875146 train accuracy = 0.8358025\n",
      "val loss = 0.27131867 val accuracy = 0.22035258\n",
      "epoch 9: train mean loss = 0.07846173 train accuracy = 0.8654321\n",
      "Final val loss = 0.27131867 val accuracy = 0.22035258\n",
      "Saving model...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "!python train_model.py --checkpoint-path {os.path.join(CHECKPOINTS_PATH, 'target_valid/catbreeds_to_butterflies/model')} \\\n",
    "                    --data-path {os.path.join(DATASET_PATH,'butterflies')} \\\n",
    "                    --mix-datasets \\\n",
    "                    --mix-data-path {os.path.join(DATASET_PATH,'catbreeds')} \\\n",
    "                    --hidden-units 32 \\\n",
    "                    --use-bias \\\n",
    "                    --freeze-output-layer \\\n",
    "                    --epochs 10 \\\n",
    "                    --val-freq 1 \\\n",
    "                    --optimizer adam \\\n",
    "                    --lr 0.0001 \\\n",
    "                    --shuffle \\\n",
    "                    --seed 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on *cat breeds* and validate on *planes*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% Validate on 'planes'\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-29 12:40:22.585946: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-05-29 12:40:22.586325: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.\n",
      "Input shape:  (1620, 25088)\n",
      "Model: \"one_hidden\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden_layer (Linear)        multiple                  802848    \n",
      "_________________________________________________________________\n",
      "output_layer (Linear)        multiple                  165       \n",
      "=================================================================\n",
      "Total params: 803,013\n",
      "Trainable params: 802,848\n",
      "Non-trainable params: 165\n",
      "_________________________________________________________________\n",
      "val loss = 0.29929802 val accuracy = 0.1698718\n",
      "epoch 0: train mean loss = 0.275201 train accuracy = 0.25555557\n",
      "val loss = 0.29414454 val accuracy = 0.17508014\n",
      "epoch 1: train mean loss = 0.21246846 train accuracy = 0.38271606\n",
      "val loss = 0.28895035 val accuracy = 0.17508014\n",
      "epoch 2: train mean loss = 0.17861284 train accuracy = 0.48209876\n",
      "val loss = 0.2866362 val accuracy = 0.17628205\n",
      "epoch 3: train mean loss = 0.15325956 train accuracy = 0.55246913\n",
      "val loss = 0.28499806 val accuracy = 0.17628205\n",
      "epoch 4: train mean loss = 0.13507222 train accuracy = 0.61851853\n",
      "val loss = 0.2838205 val accuracy = 0.16586538\n",
      "epoch 5: train mean loss = 0.11893991 train accuracy = 0.6808642\n",
      "val loss = 0.28347835 val accuracy = 0.16586538\n",
      "epoch 6: train mean loss = 0.105513684 train accuracy = 0.7475309\n",
      "val loss = 0.2830465 val accuracy = 0.16065705\n",
      "epoch 7: train mean loss = 0.09541909 train accuracy = 0.7882716\n",
      "val loss = 0.2832807 val accuracy = 0.16065705\n",
      "epoch 8: train mean loss = 0.085875146 train accuracy = 0.8358025\n",
      "val loss = 0.2823683 val accuracy = 0.16586538\n",
      "epoch 9: train mean loss = 0.07846173 train accuracy = 0.8654321\n",
      "Final val loss = 0.2823683 val accuracy = 0.16586538\n",
      "Saving model...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "!python train_model.py --checkpoint-path {os.path.join(CHECKPOINTS_PATH, 'target_valid/catbreeds_to_planes/model')} \\\n",
    "                    --data-path {os.path.join(DATASET_PATH,'planes')} \\\n",
    "                    --mix-datasets \\\n",
    "                    --mix-data-path {os.path.join(DATASET_PATH,'catbreeds')} \\\n",
    "                    --hidden-units 32 \\\n",
    "                    --use-bias \\\n",
    "                    --freeze-output-layer \\\n",
    "                    --epochs 10 \\\n",
    "                    --val-freq 1 \\\n",
    "                    --optimizer adam \\\n",
    "                    --lr 0.0001 \\\n",
    "                    --shuffle \\\n",
    "                    --seed 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell plots the results from the previous cells to reproduce Figure 1 in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% Plot results \n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zalan/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/ipykernel_launcher.py:25: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "/Users/zalan/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/ipykernel_launcher.py:30: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "/Users/zalan/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/ipykernel_launcher.py:35: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "/Users/zalan/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/ipykernel_launcher.py:41: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "/Users/zalan/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/ipykernel_launcher.py:25: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "/Users/zalan/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/ipykernel_launcher.py:30: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "/Users/zalan/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/ipykernel_launcher.py:35: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "/Users/zalan/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/ipykernel_launcher.py:41: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "/Users/zalan/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/ipykernel_launcher.py:25: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "/Users/zalan/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/ipykernel_launcher.py:30: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "/Users/zalan/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/ipykernel_launcher.py:35: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "/Users/zalan/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/ipykernel_launcher.py:41: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pathlist = Path(os.path.join(CHECKPOINTS_PATH, 'target_valid')).glob('**/*.npz')\n",
    "results = []\n",
    "target_dataset = []\n",
    "\n",
    "for path in pathlist:\n",
    "    r = np.load(path, allow_pickle=True)\n",
    "    results.append(r['arr_0'].item())\n",
    "    target_dataset.append(path.parent.name)\n",
    "\n",
    "legend_dict= {}\n",
    "for r, t in zip(results, target_dataset):\n",
    "    train_loss = r['train_loss']\n",
    "    train_acc = r['train_acc']\n",
    "    val_loss = r['val_loss']\n",
    "    val_acc = r['val_acc']\n",
    "\n",
    "    plt.figure(0)\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(train_loss, label=t)\n",
    "    plt.title('Train loss')\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(train_acc, label=t)\n",
    "    plt.title('Train acc.')\n",
    "\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(val_loss, label=t)\n",
    "    plt.legend(loc=\"upper right\", prop={'size': 6})\n",
    "    plt.title('Val loss')\n",
    "\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.plot(val_acc)\n",
    "    plt.title('Val acc.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
